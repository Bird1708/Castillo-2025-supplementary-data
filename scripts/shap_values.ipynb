{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import shap\n",
    "import warnings\n",
    "\n",
    "method = 'TCP_LT_AOF'\n",
    "data = pd.read_csv(f'../input_data/{method}/data.csv')\n",
    "\n",
    "with open(f'../results/{method}/final_hyperparameters.json', 'r') as file:\n",
    "    best_params = json.load(file)\n",
    "\n",
    "parameters = ['normal_convergence_rate', \n",
    "              'subducting_ocean_floor_age',\n",
    "              'obliquity_of_subduction',\n",
    "              'migration_rate_x_distance']\n",
    "\n",
    "X = data[parameters]\n",
    "y = data['cu_mt']\n",
    "y_cat = np.where(y > 2, 1, 0)\n",
    "\n",
    "np.random.seed(42)\n",
    "CV_iterations = 1000\n",
    "random_states = np.random.randint(9999, size=CV_iterations)\n",
    "\n",
    "# Initialize dictionaries with proper structure\n",
    "shap_values_per_cv = dict()\n",
    "for sample in X.index:\n",
    "    shap_values_per_cv[sample] = {}\n",
    "    for CV_iteration in range(CV_iterations):\n",
    "        shap_values_per_cv[sample][CV_iteration] = {}\n",
    "\n",
    "# Lists to store the performance metrics (calculated from aggregated predictions)\n",
    "roc_auc_scores, precision_scores, recall_scores, f1_score_scores = [], [], [], []\n",
    "\n",
    "# Dictionary to store confusion matrices for each CV iteration\n",
    "confusion_matrices_per_cv = {}\n",
    "\n",
    "# Repeated cross-validations\n",
    "for i, CV_iteration in enumerate(range(CV_iterations)):\n",
    "    print('\\n------------ CV Repeat number:', CV_iteration)\n",
    "    \n",
    "    CV = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_states[i])\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('model', XGBClassifier(seed=42))\n",
    "    ])\n",
    "    \n",
    "    # Store training and test indices\n",
    "    ix_training, ix_test = [], []\n",
    "    for fold in CV.split(X, y_cat):\n",
    "        ix_training.append(fold[0]), ix_test.append(fold[1])\n",
    "    \n",
    "    # Initialize lists to collect all predictions and true labels for this CV iteration\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_pred_proba = []  # For AUC calculation\n",
    "    \n",
    "    # Process each fold\n",
    "    for fold_idx, (train_outer_ix, test_outer_ix) in enumerate(zip(ix_training, ix_test)):\n",
    "        X_train, X_test = X.iloc[train_outer_ix, :], X.iloc[test_outer_ix, :]\n",
    "        y_train, y_test = y_cat[train_outer_ix], y_cat[test_outer_ix]\n",
    "        \n",
    "        pipeline.set_params(**best_params)\n",
    "        fit = pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predictions for confusion matrix and metrics\n",
    "        y_pred = fit.predict(X_test)\n",
    "        y_pred_proba = fit.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "        \n",
    "        # Collect predictions and true labels\n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        all_y_pred_proba.extend(y_pred_proba)\n",
    "        \n",
    "        model = fit.named_steps['model']\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "        # Store SHAP values and predictions for each test sample\n",
    "        for j, test_index in enumerate(test_outer_ix):\n",
    "            shap_values_per_cv[test_index][CV_iteration] = shap_values[j]\n",
    "    \n",
    "    # Create confusion matrix for this CV iteration (aggregated across all folds)\n",
    "    cm = confusion_matrix(all_y_true, all_y_pred)\n",
    "    confusion_matrices_per_cv[CV_iteration] = cm\n",
    "    \n",
    "    # Calculate all metrics from aggregated predictions\n",
    "    # AUC from probability predictions\n",
    "    roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    # Other metrics from confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Precision for positive class (High-Cu deposit detection)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    # Recall for positive class (High-Cu deposit detection)  \n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    recall_scores.append(recall)\n",
    "    \n",
    "    # F1-score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    f1_score_scores.append(f1)\n",
    "\n",
    "# Save performance metrics\n",
    "performance_metrics_df = pd.DataFrame({\n",
    "    'roc_auc': roc_auc_scores,\n",
    "    'precision': precision_scores,\n",
    "    'recall': recall_scores,\n",
    "    'f1_score': f1_score_scores\n",
    "})\n",
    "\n",
    "performance_metrics_df.to_csv('performance_metrics.csv', index=False)\n",
    "\n",
    "# Save SHAP values for each sample\n",
    "for n in range(len(data)):\n",
    "    shaps_per_obs = pd.DataFrame.from_dict(shap_values_per_cv[n])\n",
    "    shaps_per_obs.to_csv(f'sample_{n}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b3a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
